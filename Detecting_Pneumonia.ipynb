{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detecting_Pneumonia",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPORRfDWMIldvSPLhvdNT24",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shayaf84/Detecting-Pneumonia-/blob/master/Detecting_Pneumonia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZctlU25IVRy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "class pkg:\n",
        "  #### DOWNLOADING AND LOADING DATA\n",
        "  def get_metadata(metadata_path, which_splits = ['train', 'test']):  \n",
        "    '''returns metadata dataframe which contains columns of:\n",
        "       * index: index of data into numpy data\n",
        "       * class: class of image\n",
        "       * split: which dataset split is this a part of? \n",
        "    '''\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "    keep_idx = metadata['split'].isin(which_splits)\n",
        "    return metadata[keep_idx]\n",
        "\n",
        "  def get_data_split(split_name, flatten, all_data, metadata, image_shape):\n",
        "    '''\n",
        "    returns images (data), labels from folder of format [image_folder]/[split_name]/[class_name]/\n",
        "    flattens if flatten option is True \n",
        "    '''\n",
        "    sub_df = metadata[metadata['split'].isin([split_name])]\n",
        "    index  = sub_df['index'].values\n",
        "    labels = sub_df['class'].values\n",
        "    data = all_data[index,:]\n",
        "    if flatten:\n",
        "      data = data.reshape([-1, np.product(image_shape)])\n",
        "    return data, labels\n",
        "\n",
        "  def get_train_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('train', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_test_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('test', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_field_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('field', flatten, all_data, metadata, image_shape)\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import model_selection\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape, Dense, Conv2D, GlobalAveragePooling2D\n",
        "\n",
        "import keras.optimizers as optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from keras.applications import VGG16\n",
        "\n",
        "from imgaug import augmenters \n",
        "\n",
        " \n",
        "### defining project variables\n",
        "# file variables\n",
        "image_data_url       = 'https://drive.google.com/uc?id=1DNEiLAWguswhiLXGyVKsgHIRm1xZggt_'\n",
        "metadata_url         = 'https://drive.google.com/uc?id=1MW3_FU6qc0qT_uG4bzxhtEHy4Jd6dCWb'\n",
        "image_data_path      = './image_data.npy'\n",
        "metadata_path        = './metadata.csv'\n",
        "image_shape          = (64, 64, 3)\n",
        "\n",
        "\n",
        "\n",
        "###\n",
        "gdown.download(image_data_url, './image_data.npy', True)\n",
        "gdown.download(metadata_url, './metadata.csv', True)\n",
        "\n",
        "### pre-loading all data of interest\n",
        "_all_data = np.load('image_data.npy')\n",
        "_metadata = pkg.get_metadata(metadata_path, ['train','test','field'])\n",
        "\n",
        "### preparing definitions\n",
        "# downloading and loading data\n",
        "get_data_split = pkg.get_data_split\n",
        "get_metadata    = lambda :                 pkg.get_metadata(metadata_path, ['train','test'])\n",
        "get_train_data  = lambda flatten = False : pkg.get_train_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_test_data   = lambda flatten = False : pkg.get_test_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_field_data  = lambda flatten = False : pkg.get_field_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwWjy55FWJeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get a table with information about ALL of our images\n",
        "metadata = get_metadata()\n",
        "\n",
        "# what does it look like?\n",
        "metadata.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cumK389QWaw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grab our seaborn visualization toolbox!\n",
        "import seaborn as sns\n",
        "### YOUR CODE HERE\n",
        "print(metadata.groupby([\"class\"]).count())\n",
        "\n",
        "\n",
        "sns.countplot(x =\"class\", data=metadata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTs6tVtLWdOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "print(metadata.groupby([\"split\"]).count())\n",
        "\n",
        "\n",
        "sns.countplot(x =\"split\", data=metadata)\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqm_CqwqWfbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "print(metadata.groupby([\"class\",\"split\"]).count())\n",
        "\n",
        "\n",
        "sns.countplot(x =\"class\", data=metadata, hue = \"split\")\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJslGqUoWjLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_one_image(data, labels = [], index = None, image_shape = [64,64,3]):\n",
        "    '''\n",
        "    if data is a single image, display that image\n",
        "\n",
        "    if data is a 4d stack of images, display that image\n",
        "    '''\n",
        "    num_dims   = len(data.shape)\n",
        "    num_labels = len(labels)\n",
        "\n",
        "    # reshape data if necessary\n",
        "    if num_dims == 1:\n",
        "      data = data.reshape(target_shape)\n",
        "    if num_dims == 2:\n",
        "      data = data.reshape(np.vstack[-1, image_shape])\n",
        "    num_dims   = len(data.shape)\n",
        "\n",
        "    # check if single or multiple images\n",
        "    if num_dims == 3:\n",
        "      if num_labels > 1:\n",
        "        print('Multiple labels does not make sense for single image.')\n",
        "        return\n",
        "\n",
        "      label = labels      \n",
        "      if num_labels == 0:\n",
        "        label = ''\n",
        "      image = data\n",
        "\n",
        "    if num_dims == 4:\n",
        "      image = data[index, :]\n",
        "      label = labels[index]\n",
        "\n",
        "    # plot image of interest\n",
        "    print('Label: %s'%label)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plEuDME1Wycw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, train_labels = get_train_data()\n",
        "image = train_data[0,:]\n",
        "image_label = train_labels[0]\n",
        "\n",
        "test_data, test_labels = get_test_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y9cWTTXW0K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_one_image(image)\n",
        "plot_one_image(train_data,train_labels,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzPSK6sgW3nR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Here we load the train and test data for your to use.\n",
        "(train_data, train_labels) = get_train_data(flatten = True)\n",
        "(test_data, test_labels) = get_test_data(flatten = True)\n",
        "\n",
        "### Use the models specified above to fit the function to your data\n",
        "### E.g. knn = KNeighborsClassifier(n_neighbors = 5)\n",
        "### Then follow the steps in Machine Learning! Fit, Predict, and Score\n",
        "\n",
        "### YOUR CODE BELOW\n",
        "\n",
        "knn  = KNeighborsClassifier(n_neighbors=10)\n",
        "log_reg  = LogisticRegression()\n",
        "tree  = DecisionTreeClassifier(max_depth = 1000)\n",
        "\n",
        "\n",
        "knn.fit(train_data, train_labels)\n",
        "log_reg.fit(train_data, train_labels)\n",
        "tree.fit(train_data, train_labels)\n",
        "\n",
        "predictions = knn.predict(test_data)\n",
        "score = accuracy_score(test_labels, predictions)\n",
        "print(score)\n",
        "\n",
        "predictions = log_reg.predict(test_data)\n",
        "score = accuracy_score(test_labels, predictions)\n",
        "print(score)\n",
        "\n",
        "predictions = tree.predict(test_data)\n",
        "score = accuracy_score(test_labels, predictions)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWVZYEWCbcj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "    \n",
        "    history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n",
        "    ax.legend(loc = 1)    \n",
        "    ax.set_ylim([0.4, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "    \n",
        "    plt.show()\n",
        "    print(\"The highest validation accuracy was\",history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['val_accuracy'])\n",
        "    print(\"The lowest validation accuracy was\",history.sort_values(by = 'val_accuracy', ascending = True).iloc[0]['val_accuracy'])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3aeEjfITHEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(history, ax = None, xlabel = 'Epoch #'):\n",
        "    \n",
        "    history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_loss'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_loss', ascending = True).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_loss', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'loss', data = history, label = 'Training', ax = ax)\n",
        "    \n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n",
        "    ax.legend(loc = 1)    \n",
        "    ax.set_ylim([0.1, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Loss (Fraction)')\n",
        "    \n",
        "    plt.show()\n",
        "    print(\"The lowest validation loss was\",history.sort_values(by = 'val_loss', ascending = True).iloc[0]['val_loss'])\n",
        "    print(\"The highest validation loss was\",history.sort_values(by = 'val_loss', ascending = False).iloc[0]['val_loss'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbg_OgRiyBKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Reshape((64,64,3)))\n",
        "model.add(Conv2D(32, (3, 3), padding = 'same', \\\n",
        "                 activation=\"relu\",input_shape = (2000,64,64,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(32, (3, 3), padding = 'same',activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten()) \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "opt = keras.optimizers.rmsprop(lr=1e-4, decay=1e-6)\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics=['accuracy']) \n",
        "\n",
        "monitor = ModelCheckpoint('./model.h5', monitor='val_acc', verbose=0,\\\n",
        "                          save_best_only=True, save_weights_only=False,\\\n",
        "                          mode='auto', period=1)\n",
        "\n",
        "\n",
        "history = model.fit(train_data, train_labels, epochs = 15,\\\n",
        "                    validation_data = (test_data, test_labels),callbacks=[monitor])\n",
        "\n",
        "plot_acc(history)\n",
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE3O_J1BRbmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "expert_conv = VGG16(weights = 'imagenet', include_top = False,input_shape=(64,64,3))\n",
        "\n",
        "for layer in expert_conv.layers:\n",
        "      trainable = True\n",
        "      layer.trainable = trainable\n",
        "\n",
        "\n",
        "expert_model = Sequential()\n",
        "expert_model.add(Reshape((64,64,3)))\n",
        "expert_model.add(expert_conv)\n",
        "expert_model.add(GlobalAveragePooling2D())\n",
        "\n",
        "expert_model.add(Dense(128, activation = 'relu'))\n",
        "expert_model.add(Dropout(0.3))\n",
        "expert_model.add(Dense(64, activation = 'relu'))\n",
        "expert_model.add(Dense(1, activation = \"sigmoid\"))\n",
        "\n",
        "opt = keras.optimizers.SGD(lr=1e-4, momentum=0.95)\n",
        "\n",
        "expert_model.compile(loss = \"binary_crossentropy\", optimizer = opt, metrics=['accuracy'])\n",
        "history =expert_model.fit(train_data,train_labels,validation_data=(test_data,test_labels),epochs = 3)\n",
        "plot_acc(history)\n",
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}